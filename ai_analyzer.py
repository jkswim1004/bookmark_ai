"""
AI ê¸°ë°˜ ì‚¬ìš©ì ì„±í–¥ ë¶„ì„ ëª¨ë“ˆ
OpenAI GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆ˜ì§‘ëœ ë°ì´í„°ë¡œë¶€í„° ì‹¬ì¸µì ì¸ ì¸ì‚¬ì´íŠ¸ ìƒì„±
"""
import json
import os
from datetime import datetime
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
try:
    from dotenv import load_dotenv
    load_dotenv()  # .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
    print("âœ… .env íŒŒì¼ ë¡œë“œ ì„±ê³µ")
except ImportError:
    print("âš ï¸ python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install python-dotenvë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")

# OpenAI API ì„¤ì •
try:
    import openai
    OPENAI_AVAILABLE = True
    print("âœ… OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì„±ê³µ")
except ImportError:
    OPENAI_AVAILABLE = False
    print("âš ï¸ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install openaië¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")

def convert_numpy_types(obj):
    """numpy íƒ€ì…ì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜"""
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(item) for item in obj]
    else:
        return obj

class AIPersonalityAnalyzer:
    def __init__(self, api_key: Optional[str] = None):
        """AI ì„±í–¥ ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        
        if OPENAI_AVAILABLE and self.api_key:
            try:
                # OpenAI v1.0+ ë°©ì‹ìœ¼ë¡œ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
                self.client = openai.OpenAI(api_key=self.api_key)
                self.ai_enabled = True
                print(f"âœ… OpenAI API ì—°ê²° ì„±ê³µ (í‚¤: {self.api_key[:7]}...{self.api_key[-7:]})")
            except Exception as e:
                print(f"âŒ OpenAI API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.ai_enabled = False
        else:
            self.ai_enabled = False
            print(f"âš ï¸ OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë¶„ì„ ëª¨ë“œë¡œ ì‘ë™í•©ë‹ˆë‹¤. (í‚¤: {self.api_key})")
    
    def analyze_user_profile(self, data_summary: Dict[str, Any]) -> Dict[str, Any]:
        """ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ì¢…í•©í•˜ì—¬ ì‚¬ìš©ì í”„ë¡œí•„ ë¶„ì„"""
        print(f"ğŸ” AI ë¶„ì„ ì‹œì‘ - AI í™œì„±í™” ìƒíƒœ: {self.ai_enabled}")
        print(f"ğŸ”‘ API í‚¤ ì¡´ì¬: {bool(self.api_key)}")
        
        if not self.ai_enabled:
            print("âš ï¸ AIê°€ ë¹„í™œì„±í™”ë˜ì–´ ê¸°ë³¸ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
            return self._get_basic_analysis(data_summary)
        
        try:
            print("ğŸš€ AI ê¸°ë°˜ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            
            # AI ë¶„ì„ ìˆ˜í–‰
            print("ğŸ“Š AI ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘...")
            ai_insights = self._generate_ai_insights(data_summary)
            
            print("ğŸ§  MBTI ë¶„ì„ ì¤‘...")
            mbti_analysis = self._analyze_mbti(data_summary)
            
            print("ğŸ¯ ì„±ê²© íŠ¹ì„± ë¶„ì„ ì¤‘...")
            personality_traits = self._analyze_personality_traits(data_summary)
            
            print("ğŸ’¡ ì¶”ì²œ ìƒì„± ì¤‘...")
            recommendations = self._generate_recommendations(data_summary)
            
            print("âœ… AI ë¶„ì„ ì™„ë£Œ!")
            return {
                'ai_insights': ai_insights,
                'mbti_analysis': mbti_analysis,
                'personality_traits': personality_traits,
                'recommendations': recommendations,
                'analysis_timestamp': datetime.now().isoformat(),
                'ai_powered': True
            }
        except Exception as e:
            print(f"âŒ AI ë¶„ì„ ì‹¤íŒ¨, ê¸°ë³¸ ë¶„ì„ìœ¼ë¡œ ì „í™˜: {e}")
            import traceback
            traceback.print_exc()
            return self._get_basic_analysis(data_summary)
    
    def _generate_ai_insights(self, data_summary: Dict[str, Any]) -> Dict[str, str]:
        """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì¢…í•©ì ì¸ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        prompt = self._create_analysis_prompt(data_summary)
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": """ë‹¹ì‹ ì€ ë””ì§€í„¸ í–‰ë™ íŒ¨í„´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
                        ì‚¬ìš©ìì˜ ë¸Œë¼ìš°ì € ì‚¬ìš© íŒ¨í„´, ì„¤ì¹˜ëœ í”„ë¡œê·¸ë¨, íŒŒì¼ ì‚¬ìš© í˜„í™©ì„ ë°”íƒ•ìœ¼ë¡œ 
                        ì„±ê²©, ì—…ë¬´ ìŠ¤íƒ€ì¼, ê´€ì‹¬ì‚¬ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”. 
                        í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=1000,
                temperature=0.7
            )
            
            ai_response = response.choices[0].message.content
            
            # ì‘ë‹µì„ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ íŒŒì‹±
            return self._parse_ai_response(ai_response)
            
        except Exception as e:
            print(f"AI ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'overview': 'ë°ì´í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
                'strengths': 'ë¶„ì„í•  ìˆ˜ ì—†ìŒ',
                'work_style': 'ë¶„ì„í•  ìˆ˜ ì—†ìŒ',
                'interests': 'ë¶„ì„í•  ìˆ˜ ì—†ìŒ'
            }
    
    def _analyze_mbti(self, data_summary: Dict[str, Any]) -> Dict[str, Any]:
        """MBTI ì„±í–¥ ë¶„ì„"""
        if not self.ai_enabled:
            return self._get_basic_mbti()
        
        mbti_prompt = f"""
        ë‹¤ìŒ ì‚¬ìš©ì ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ MBTI ì„±í–¥ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
        
        ë¸Œë¼ìš°ì € ì‚¬ìš© íŒ¨í„´: {data_summary.get('browser_patterns', {})}
        ì„¤ì¹˜ëœ í”„ë¡œê·¸ë¨: {data_summary.get('software_categories', {})}
        íŒŒì¼ ì‚¬ìš© íŒ¨í„´: {data_summary.get('file_patterns', {})}
        ë„¤íŠ¸ì›Œí¬ í™œë™: {data_summary.get('network_activity', {})}
        
        ê° MBTI ì°¨ì›ì— ëŒ€í•´ 0-100 ì ìˆ˜ë¡œ í‰ê°€í•˜ê³  ê·¼ê±°ë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”:
        - E(ì™¸í–¥ì„±) vs I(ë‚´í–¥ì„±)
        - S(ê°ê°) vs N(ì§ê´€)  
        - T(ì‚¬ê³ ) vs F(ê°ì •)
        - J(íŒë‹¨) vs P(ì¸ì‹)
        
        JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ MBTI ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë””ì§€í„¸ ì‚¬ìš© íŒ¨í„´ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ MBTI ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": mbti_prompt
                    }
                ],
                max_tokens=800,
                temperature=0.5
            )
            
            mbti_response = response.choices[0].message.content
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                return json.loads(mbti_response)
            except:
                return self._parse_mbti_text(mbti_response)
                
        except Exception as e:
            print(f"MBTI ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._get_basic_mbti()
    
    def _analyze_personality_traits(self, data_summary: Dict[str, Any]) -> Dict[str, Any]:
        """ì„±ê²© íŠ¹ì„± ë¶„ì„ (Big 5 ë“±)"""
        if not self.ai_enabled:
            return self._get_basic_personality()
        
        # numpy íƒ€ì…ì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
        clean_data = convert_numpy_types(data_summary)
        
        traits_prompt = f"""
        ë‹¤ìŒ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì„±ê²© íŠ¹ì„±ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
        
        {json.dumps(clean_data, ensure_ascii=False, indent=2)}
        
        ë‹¤ìŒ íŠ¹ì„±ë“¤ì„ 0-100 ì ìˆ˜ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”:
        - ê°œë°©ì„± (ìƒˆë¡œìš´ ê²½í—˜ì— ëŒ€í•œ ê°œë°©ì„±)
        - ì„±ì‹¤ì„± (ì¡°ì§ì ì´ê³  ê³„íšì ì¸ ì„±í–¥)
        - ì™¸í–¥ì„± (ì‚¬êµì ì´ê³  í™œë™ì ì¸ ì„±í–¥)
        - ì¹œí™”ì„± (í˜‘ë ¥ì ì´ê³  ì‹ ë¢°í•˜ëŠ” ì„±í–¥)
        - ì‹ ê²½ì„± (ìŠ¤íŠ¸ë ˆìŠ¤ì— ëŒ€í•œ ë¯¼ê°ì„±)
        - ì°½ì˜ì„± (ì°½ì˜ì  ì‚¬ê³ ì™€ í˜ì‹ ì„±)
        - ê¸°ìˆ  ì¹œí™”ë„ (ê¸°ìˆ  ìˆ˜ìš©ê³¼ í™œìš© ëŠ¥ë ¥)
        
        ê° ì ìˆ˜ì— ëŒ€í•œ ê·¼ê±°ë„ í•¨ê»˜ ì œì‹œí•´ì£¼ì„¸ìš”.
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ì‹¬ë¦¬í•™ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë””ì§€í„¸ í–‰ë™ íŒ¨í„´ì„ í†µí•´ ì„±ê²© íŠ¹ì„±ì„ ì •í™•íˆ ë¶„ì„í•´ì£¼ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": traits_prompt
                    }
                ],
                max_tokens=1000,
                temperature=0.6
            )
            
            return self._parse_personality_response(response.choices[0].message.content)
            
        except Exception as e:
            print(f"ì„±ê²© íŠ¹ì„± ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._get_basic_personality()
    
    def _generate_recommendations(self, data_summary: Dict[str, Any]) -> Dict[str, List[str]]:
        """ê°œì¸í™”ëœ ì¶”ì²œ ìƒì„±"""
        if not self.ai_enabled:
            return self._get_basic_recommendations()
        
        # numpy íƒ€ì…ì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
        clean_data = convert_numpy_types(data_summary)
        
        rec_prompt = f"""
        ë‹¤ìŒ ì‚¬ìš©ì í”„ë¡œí•„ì„ ë°”íƒ•ìœ¼ë¡œ ê°œì¸í™”ëœ ì¶”ì²œì„ ìƒì„±í•´ì£¼ì„¸ìš”:
        
        {json.dumps(clean_data, ensure_ascii=False, indent=2)}
        
        ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë³„ë¡œ êµ¬ì²´ì ì¸ ì¶”ì²œì„ ì œì‹œí•´ì£¼ì„¸ìš”:
        1. ìƒì‚°ì„± ë„êµ¬ (ì—…ë¬´ íš¨ìœ¨ì„± í–¥ìƒ)
        2. í•™ìŠµ ë¦¬ì†ŒìŠ¤ (ê¸°ìˆ  ë° ì§€ì‹ í–¥ìƒ)
        3. ì†Œí”„íŠ¸ì›¨ì–´/ì•± (í˜„ì¬ ì‚¬ìš© íŒ¨í„´ ê¸°ë°˜)
        4. ì—…ë¬´ ìŠ¤íƒ€ì¼ ê°œì„  (ë” ë‚˜ì€ ì‘ì—… í™˜ê²½)
        5. ì»¤ë¦¬ì–´ ë°œì „ (ì„±í–¥ì— ë§ëŠ” ë°©í–¥ì„±)
        
        ê° ì¹´í…Œê³ ë¦¬ë‹¹ 3-5ê°œì˜ êµ¬ì²´ì ì¸ ì¶”ì²œì„ í•´ì£¼ì„¸ìš”.
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ê°œì¸ ìƒì‚°ì„± ë° ì»¤ë¦¬ì–´ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ë””ì§€í„¸ íŒ¨í„´ì„ ë°”íƒ•ìœ¼ë¡œ ì‹¤ìš©ì ì¸ ì¶”ì²œì„ ì œê³µí•´ì£¼ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": rec_prompt
                    }
                ],
                max_tokens=1200,
                temperature=0.7
            )
            
            return self._parse_recommendations_response(response.choices[0].message.content)
            
        except Exception as e:
            print(f"ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: {e}")
            return self._get_basic_recommendations()
    
    def _create_analysis_prompt(self, data_summary: Dict[str, Any]) -> str:
        """ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return f"""
        ì‚¬ìš©ìì˜ ë””ì§€í„¸ ì‚¬ìš© íŒ¨í„´ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
        
        ğŸ“Š ìˆ˜ì§‘ëœ ë°ì´í„°:
        - ë¶ë§ˆí¬ ì¹´í…Œê³ ë¦¬: {data_summary.get('bookmark_categories', [])}
        - ë¸Œë¼ìš°ì € íˆìŠ¤í† ë¦¬: {data_summary.get('top_sites', [])}
        - ì„¤ì¹˜ëœ í”„ë¡œê·¸ë¨: {data_summary.get('software_categories', {})}
        - Chrome í™•ì¥ í”„ë¡œê·¸ë¨: {data_summary.get('extensions', [])}
        - ìµœê·¼ ì‚¬ìš© íŒŒì¼: {data_summary.get('recent_files', [])}
        - ë„¤íŠ¸ì›Œí¬ í™œë™: {data_summary.get('network_stats', {})}
        
        ğŸ“ˆ í†µê³„:
        - ì´ ë¶ë§ˆí¬ ìˆ˜: {data_summary.get('total_bookmarks', 0)}
        - ì´ ë°©ë¬¸ ì‚¬ì´íŠ¸: {data_summary.get('total_visits', 0)}
        - ì„¤ì¹˜ëœ í”„ë¡œê·¸ë¨ ìˆ˜: {data_summary.get('total_programs', 0)}
        
        ì´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
        1. ì „ë°˜ì ì¸ ë””ì§€í„¸ ì‚¬ìš© ì„±í–¥
        2. ì£¼ìš” ê°•ì ê³¼ íŠ¹ì§•
        3. ì—…ë¬´ ìŠ¤íƒ€ì¼ê³¼ ì„ í˜¸ë„
        4. ê´€ì‹¬ ë¶„ì•¼ì™€ ì „ë¬¸ì„±
        """
    
    def _parse_ai_response(self, response: str) -> Dict[str, str]:
        """AI ì‘ë‹µì„ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ íŒŒì‹±"""
        # ê°„ë‹¨í•œ íŒŒì‹± ë¡œì§ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ íŒŒì‹±ì´ í•„ìš”)
        lines = response.split('\n')
        
        result = {
            'overview': '',
            'strengths': '',
            'work_style': '',
            'interests': ''
        }
        
        current_section = 'overview'
        for line in lines:
            line = line.strip()
            if 'ê°•ì ' in line or 'strength' in line.lower():
                current_section = 'strengths'
            elif 'ì—…ë¬´' in line or 'work' in line.lower():
                current_section = 'work_style'
            elif 'ê´€ì‹¬' in line or 'interest' in line.lower():
                current_section = 'interests'
            elif line:
                result[current_section] += line + ' '
        
        return result
    
    def _parse_mbti_text(self, response: str) -> Dict[str, Any]:
        """MBTI í…ìŠ¤íŠ¸ ì‘ë‹µ íŒŒì‹±"""
        return {
            'E_I': {'score': 65, 'tendency': 'E', 'description': 'AI ë¶„ì„ ê²°ê³¼ë¥¼ íŒŒì‹±í•˜ëŠ” ì¤‘...'},
            'S_N': {'score': 45, 'tendency': 'S', 'description': 'AI ë¶„ì„ ê²°ê³¼ë¥¼ íŒŒì‹±í•˜ëŠ” ì¤‘...'},
            'T_F': {'score': 70, 'tendency': 'T', 'description': 'AI ë¶„ì„ ê²°ê³¼ë¥¼ íŒŒì‹±í•˜ëŠ” ì¤‘...'},
            'J_P': {'score': 55, 'tendency': 'J', 'description': 'AI ë¶„ì„ ê²°ê³¼ë¥¼ íŒŒì‹±í•˜ëŠ” ì¤‘...'},
            'predicted_type': 'ESTJ',
            'confidence': 75
        }
    
    def _parse_personality_response(self, response: str) -> Dict[str, Any]:
        """ì„±ê²© íŠ¹ì„± ì‘ë‹µ íŒŒì‹±"""
        return {
            'openness': {'score': 75, 'description': 'AI ë¶„ì„ ì¤‘...'},
            'conscientiousness': {'score': 68, 'description': 'AI ë¶„ì„ ì¤‘...'},
            'extraversion': {'score': 62, 'description': 'AI ë¶„ì„ ì¤‘...'},
            'agreeableness': {'score': 71, 'description': 'AI ë¶„ì„ ì¤‘...'},
            'neuroticism': {'score': 35, 'description': 'AI ë¶„ì„ ì¤‘...'},
            'creativity': {'score': 78, 'description': 'AI ë¶„ì„ ì¤‘...'},
            'tech_savviness': {'score': 85, 'description': 'AI ë¶„ì„ ì¤‘...'}
        }
    
    def _parse_recommendations_response(self, response: str) -> Dict[str, List[str]]:
        """ì¶”ì²œ ì‘ë‹µ íŒŒì‹±"""
        return {
            'productivity_tools': ['AI ë¶„ì„ ê¸°ë°˜ ì¶”ì²œì„ ìƒì„±í•˜ëŠ” ì¤‘...'],
            'learning_resources': ['AI ë¶„ì„ ê¸°ë°˜ ì¶”ì²œì„ ìƒì„±í•˜ëŠ” ì¤‘...'],
            'software_apps': ['AI ë¶„ì„ ê¸°ë°˜ ì¶”ì²œì„ ìƒì„±í•˜ëŠ” ì¤‘...'],
            'work_style': ['AI ë¶„ì„ ê¸°ë°˜ ì¶”ì²œì„ ìƒì„±í•˜ëŠ” ì¤‘...'],
            'career_development': ['AI ë¶„ì„ ê¸°ë°˜ ì¶”ì²œì„ ìƒì„±í•˜ëŠ” ì¤‘...']
        }
    
    def _get_basic_analysis(self, data_summary: Dict[str, Any]) -> Dict[str, Any]:
        """AI ì—†ì´ ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰"""
        return {
            'ai_insights': {
                'overview': 'ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¸°ë³¸ ë¶„ì„ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.',
                'strengths': 'ë‹¤ì–‘í•œ ë””ì§€í„¸ ë„êµ¬ë¥¼ í™œìš©í•˜ëŠ” ëŠ¥ë ¥ì´ ìˆìŠµë‹ˆë‹¤.',
                'work_style': 'ì²´ê³„ì ì´ê³  íš¨ìœ¨ì ì¸ ì‘ì—… ë°©ì‹ì„ ì„ í˜¸í•©ë‹ˆë‹¤.',
                'interests': 'ê¸°ìˆ ê³¼ ìƒì‚°ì„±ì— ê´€ì‹¬ì´ ë§ìŠµë‹ˆë‹¤.'
            },
            'mbti_analysis': self._get_basic_mbti(),
            'personality_traits': self._get_basic_personality(),
            'recommendations': self._get_basic_recommendations(),
            'analysis_timestamp': datetime.now().isoformat(),
            'ai_powered': False
        }
    
    def _get_basic_mbti(self) -> Dict[str, Any]:
        """ê¸°ë³¸ MBTI ë¶„ì„"""
        return {
            'E_I': {'score': 60, 'tendency': 'E', 'description': 'ì†Œì…œ ë„êµ¬ ì‚¬ìš© íŒ¨í„´ ê¸°ë°˜ ë¶„ì„'},
            'S_N': {'score': 45, 'tendency': 'S', 'description': 'ì‹¤ìš©ì  ë„êµ¬ ì„ í˜¸ ê²½í–¥'},
            'T_F': {'score': 65, 'tendency': 'T', 'description': 'ë…¼ë¦¬ì  ë„êµ¬ ì‚¬ìš© íŒ¨í„´'},
            'J_P': {'score': 55, 'tendency': 'J', 'description': 'ì²´ê³„ì  íŒŒì¼ ê´€ë¦¬ íŒ¨í„´'},
            'predicted_type': 'ESTJ',
            'confidence': 60
        }
    
    def _get_basic_personality(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ì„±ê²© íŠ¹ì„±"""
        return {
            'openness': {'score': 70, 'description': 'ë‹¤ì–‘í•œ ë„êµ¬ì™€ ê¸°ìˆ  ì‚¬ìš©'},
            'conscientiousness': {'score': 65, 'description': 'ì²´ê³„ì ì¸ íŒŒì¼ ê´€ë¦¬'},
            'extraversion': {'score': 60, 'description': 'í˜‘ì—… ë„êµ¬ ì‚¬ìš© íŒ¨í„´'},
            'agreeableness': {'score': 70, 'description': 'ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ë„êµ¬ í™œìš©'},
            'neuroticism': {'score': 40, 'description': 'ì•ˆì •ì ì¸ ì‚¬ìš© íŒ¨í„´'},
            'creativity': {'score': 75, 'description': 'ì°½ì‘ ë„êµ¬ ì‚¬ìš©'},
            'tech_savviness': {'score': 80, 'description': 'ê³ ê¸‰ ê¸°ìˆ  ë„êµ¬ í™œìš©'}
        }
    
    def _get_basic_recommendations(self) -> Dict[str, List[str]]:
        """ê¸°ë³¸ ì¶”ì²œ"""
        return {
            'productivity_tools': [
                'Notion - í†µí•© ì›Œí¬ìŠ¤í˜ì´ìŠ¤',
                'Todoist - ì‘ì—… ê´€ë¦¬',
                'RescueTime - ì‹œê°„ ì¶”ì '
            ],
            'learning_resources': [
                'Coursera - ì˜¨ë¼ì¸ ê°•ì˜',
                'Udemy - ê¸°ìˆ  êµìœ¡',
                'LinkedIn Learning - ì „ë¬¸ ìŠ¤í‚¬'
            ],
            'software_apps': [
                'VS Code - ì½”ë“œ ì—ë””í„°',
                'Figma - ë””ìì¸ ë„êµ¬',
                'Slack - íŒ€ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜'
            ],
            'work_style': [
                'í¬ëª¨ë„ë¡œ ê¸°ë²• í™œìš©',
                'ì •ê¸°ì ì¸ ë°±ì—… ìŠµê´€',
                'í‚¤ë³´ë“œ ë‹¨ì¶•í‚¤ í•™ìŠµ'
            ],
            'career_development': [
                'ê¸°ìˆ  ë¸”ë¡œê·¸ ì‘ì„±',
                'ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ ì°¸ì—¬',
                'ì˜¨ë¼ì¸ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì¶•'
            ]
        }

def prepare_data_for_ai_analysis(uploads_dir: str) -> Dict[str, Any]:
    """ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ AI ë¶„ì„ìš©ìœ¼ë¡œ ì¤€ë¹„"""
    data_summary = {
        'bookmark_categories': [],
        'top_sites': [],
        'software_categories': {},
        'extensions': [],
        'recent_files': [],
        'network_stats': {},
        'total_bookmarks': 0,
        'total_visits': 0,
        'total_programs': 0
    }
    
    try:
        # ë¶ë§ˆí¬ ë°ì´í„° ì²˜ë¦¬
        bookmark_files = [f for f in os.listdir(uploads_dir) if f.startswith('bookmarks_') and f.endswith('.csv')]
        if bookmark_files:
            latest_bookmark = max(bookmark_files, key=lambda f: os.path.getctime(os.path.join(uploads_dir, f)))
            df_bookmarks = pd.read_csv(os.path.join(uploads_dir, latest_bookmark))
            
            if 'folder' in df_bookmarks.columns:
                data_summary['bookmark_categories'] = df_bookmarks['folder'].value_counts().head(10).to_dict()
            data_summary['total_bookmarks'] = len(df_bookmarks)
        
        # íˆìŠ¤í† ë¦¬ ë°ì´í„° ì²˜ë¦¬
        history_files = [f for f in os.listdir(uploads_dir) if f.startswith('browser_history_') and f.endswith('.csv')]
        if history_files:
            latest_history = max(history_files, key=lambda f: os.path.getctime(os.path.join(uploads_dir, f)))
            df_history = pd.read_csv(os.path.join(uploads_dir, latest_history))
            
            if 'domain' in df_history.columns:
                data_summary['top_sites'] = df_history['domain'].value_counts().head(10).to_dict()
            if 'visit_count' in df_history.columns:
                data_summary['total_visits'] = df_history['visit_count'].sum()
        
        # í™•ì¥ í”„ë¡œê·¸ë¨ ë°ì´í„° ì²˜ë¦¬
        extension_files = [f for f in os.listdir(uploads_dir) if f.startswith('chrome_extensions_') and f.endswith('.csv')]
        if extension_files:
            latest_extensions = max(extension_files, key=lambda f: os.path.getctime(os.path.join(uploads_dir, f)))
            df_extensions = pd.read_csv(os.path.join(uploads_dir, latest_extensions))
            
            if 'category' in df_extensions.columns:
                data_summary['extensions'] = df_extensions['category'].value_counts().to_dict()
        
        # ì„¤ì¹˜ëœ í”„ë¡œê·¸ë¨ ë°ì´í„° ì²˜ë¦¬
        program_files = [f for f in os.listdir(uploads_dir) if f.startswith('installed_programs_') and f.endswith('.csv')]
        if program_files:
            latest_programs = max(program_files, key=lambda f: os.path.getctime(os.path.join(uploads_dir, f)))
            df_programs = pd.read_csv(os.path.join(uploads_dir, latest_programs))
            
            if 'category' in df_programs.columns:
                data_summary['software_categories'] = df_programs['category'].value_counts().to_dict()
            data_summary['total_programs'] = len(df_programs)
        
        # ìµœê·¼ íŒŒì¼ ë°ì´í„° ì²˜ë¦¬
        recent_files = [f for f in os.listdir(uploads_dir) if f.startswith('recent_files_') and f.endswith('.csv')]
        if recent_files:
            latest_recent = max(recent_files, key=lambda f: os.path.getctime(os.path.join(uploads_dir, f)))
            df_recent = pd.read_csv(os.path.join(uploads_dir, latest_recent))
            
            if 'category' in df_recent.columns:
                data_summary['recent_files'] = df_recent['category'].value_counts().to_dict()
        
        # ë„¤íŠ¸ì›Œí¬ ì •ë³´ ì²˜ë¦¬
        network_files = [f for f in os.listdir(uploads_dir) if f.startswith('network_info_') and f.endswith('.csv')]
        if network_files:
            latest_network = max(network_files, key=lambda f: os.path.getctime(os.path.join(uploads_dir, f)))
            df_network = pd.read_csv(os.path.join(uploads_dir, latest_network))
            
            if 'category' in df_network.columns:
                data_summary['network_stats'] = df_network['category'].value_counts().to_dict()
    
    except Exception as e:
        print(f"ë°ì´í„° ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜: {e}")
    
    # numpy íƒ€ì…ì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
    return convert_numpy_types(data_summary)
