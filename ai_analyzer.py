"""
AI ê¸°ë°˜ ì‚¬ìš©ì ì„±í–¥ ë¶„ì„ ëª¨ë“ˆ
OpenAI GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆ˜ì§‘ëœ ë°ì´í„°ë¡œë¶€í„° ì‹¬ì¸µì ì¸ ì¸ì‚¬ì´íŠ¸ ìƒì„±
"""
import json
import os
from datetime import datetime
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
try:
    from dotenv import load_dotenv
    load_dotenv()  # .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
    print("âœ… .env íŒŒì¼ ë¡œë“œ ì„±ê³µ")
except ImportError:
    print("âš ï¸ python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install python-dotenvë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")

# OpenAI API ì„¤ì •
try:
    import openai
    OPENAI_AVAILABLE = True
    print("âœ… OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì„±ê³µ")
except ImportError:
    OPENAI_AVAILABLE = False
    print("âš ï¸ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install openaië¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")

def convert_numpy_types(obj):
    """numpy íƒ€ì…ì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜"""
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(item) for item in obj]
    else:
        return obj

class AIPersonalityAnalyzer:
    def __init__(self, api_key: Optional[str] = None):
        """AI ì„±í–¥ ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        
        if OPENAI_AVAILABLE and self.api_key:
            try:
                # OpenAI v1.0+ ë°©ì‹ìœ¼ë¡œ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
                self.client = openai.OpenAI(api_key=self.api_key)
                self.ai_enabled = True
                print(f"âœ… OpenAI API ì—°ê²° ì„±ê³µ (í‚¤: {self.api_key[:7]}...{self.api_key[-7:]})")
            except Exception as e:
                print(f"âŒ OpenAI API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.ai_enabled = False
        else:
            self.ai_enabled = False
            print(f"âš ï¸ OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë¶„ì„ ëª¨ë“œë¡œ ì‘ë™í•©ë‹ˆë‹¤. (í‚¤: {self.api_key})")
    
    def analyze_user_profile(self, data_summary: Dict[str, Any]) -> Dict[str, Any]:
        """ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ì¢…í•©í•˜ì—¬ ì‚¬ìš©ì í”„ë¡œí•„ ë¶„ì„"""
        print(f"ğŸ” AI ë¶„ì„ ì‹œì‘ - AI í™œì„±í™” ìƒíƒœ: {self.ai_enabled}")
        print(f"ğŸ”‘ API í‚¤ ì¡´ì¬: {bool(self.api_key)}")
        
        if not self.ai_enabled:
            print("âš ï¸ AIê°€ ë¹„í™œì„±í™”ë˜ì–´ ê¸°ë³¸ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
            return self._get_basic_analysis(data_summary)
        
        try:
            print("ğŸš€ AI ê¸°ë°˜ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            
            # AI ë¶„ì„ ìˆ˜í–‰
            print("ğŸ“Š AI ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘...")
            ai_insights = self._generate_ai_insights(data_summary)
            
            print("ğŸ§  MBTI ë¶„ì„ ì¤‘...")
            mbti_analysis = self._analyze_mbti(data_summary)
            
            print("ğŸ¯ ì„±ê²© íŠ¹ì„± ë¶„ì„ ì¤‘...")
            personality_traits = self._analyze_personality_traits(data_summary)
            
            print("ğŸ’¡ ì¶”ì²œ ìƒì„± ì¤‘...")
            recommendations = self._generate_recommendations(data_summary)
            
            print("âœ… AI ë¶„ì„ ì™„ë£Œ!")
            return {
                'ai_insights': ai_insights,
                'mbti_analysis': mbti_analysis,
                'personality_traits': personality_traits,
                'recommendations': recommendations,
                'analysis_timestamp': datetime.now().isoformat(),
                'ai_powered': True
            }
        except Exception as e:
            print(f"âŒ AI ë¶„ì„ ì‹¤íŒ¨, ê¸°ë³¸ ë¶„ì„ìœ¼ë¡œ ì „í™˜: {e}")
            import traceback
            traceback.print_exc()
            return self._get_basic_analysis(data_summary)
    
    def _generate_ai_insights(self, data_summary: Dict[str, Any]) -> Dict[str, str]:
        """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì¢…í•©ì ì¸ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        prompt = self._create_analysis_prompt(data_summary)
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": """ë‹¹ì‹ ì€ ë””ì§€í„¸ í–‰ë™ íŒ¨í„´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
                        ì‚¬ìš©ìì˜ ë¸Œë¼ìš°ì € ì‚¬ìš© íŒ¨í„´, ì„¤ì¹˜ëœ í”„ë¡œê·¸ë¨, íŒŒì¼ ì‚¬ìš© í˜„í™©ì„ ë°”íƒ•ìœ¼ë¡œ 
                        ì„±ê²©, ì—…ë¬´ ìŠ¤íƒ€ì¼, ê´€ì‹¬ì‚¬ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”. 
                        í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=1000,
                temperature=0.7
            )
            
            ai_response = response.choices[0].message.content
            
            # ì‘ë‹µì„ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ íŒŒì‹±
            return self._parse_ai_response(ai_response)
            
        except Exception as e:
            print(f"AI ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'overview': 'ë°ì´í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
                'strengths': 'ë¶„ì„í•  ìˆ˜ ì—†ìŒ',
                'work_style': 'ë¶„ì„í•  ìˆ˜ ì—†ìŒ',
                'interests': 'ë¶„ì„í•  ìˆ˜ ì—†ìŒ'
            }
    
    def _analyze_mbti(self, data_summary: Dict[str, Any]) -> Dict[str, Any]:
        """MBTI ì„±í–¥ ë¶„ì„"""
        if not self.ai_enabled:
            return self._get_basic_mbti()
        
        mbti_prompt = f"""
        ë‹¤ìŒ ì‚¬ìš©ì ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ MBTI ì„±í–¥ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
        
        ë¸Œë¼ìš°ì € ì‚¬ìš© íŒ¨í„´: {data_summary.get('browser_patterns', {})}
        ì„¤ì¹˜ëœ í”„ë¡œê·¸ë¨: {data_summary.get('software_categories', {})}
        íŒŒì¼ ì‚¬ìš© íŒ¨í„´: {data_summary.get('file_patterns', {})}
        ë„¤íŠ¸ì›Œí¬ í™œë™: {data_summary.get('network_activity', {})}
        
        ê° MBTI ì°¨ì›ì— ëŒ€í•´ 0-100 ì ìˆ˜ë¡œ í‰ê°€í•˜ê³  ê·¼ê±°ë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”:
        - E(ì™¸í–¥ì„±) vs I(ë‚´í–¥ì„±)
        - S(ê°ê°) vs N(ì§ê´€)  
        - T(ì‚¬ê³ ) vs F(ê°ì •)
        - J(íŒë‹¨) vs P(ì¸ì‹)
        
        JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ MBTI ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë””ì§€í„¸ ì‚¬ìš© íŒ¨í„´ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ MBTI ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": mbti_prompt
                    }
                ],
                max_tokens=800,
                temperature=0.5
            )
            
            mbti_response = response.choices[0].message.content
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                return json.loads(mbti_response)
            except:
                return self._parse_mbti_text(mbti_response)
                
        except Exception as e:
            print(f"MBTI ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._get_basic_mbti()
    
    def _analyze_personality_traits(self, data_summary: Dict[str, Any]) -> Dict[str, Any]:
        """ì„±ê²© íŠ¹ì„± ë¶„ì„ (Big 5 ë“±)"""
        if not self.ai_enabled:
            return self._get_basic_personality()
        
        # numpy íƒ€ì…ì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
        clean_data = convert_numpy_types(data_summary)
        
        traits_prompt = f"""
        ë‹¤ìŒ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì„±ê²© íŠ¹ì„±ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
        
        {json.dumps(clean_data, ensure_ascii=False, indent=2)}
        
        ë‹¤ìŒ íŠ¹ì„±ë“¤ì„ 0-100 ì ìˆ˜ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”:
        - ê°œë°©ì„± (ìƒˆë¡œìš´ ê²½í—˜ì— ëŒ€í•œ ê°œë°©ì„±)
        - ì„±ì‹¤ì„± (ì¡°ì§ì ì´ê³  ê³„íšì ì¸ ì„±í–¥)
        - ì™¸í–¥ì„± (ì‚¬êµì ì´ê³  í™œë™ì ì¸ ì„±í–¥)
        - ì¹œí™”ì„± (í˜‘ë ¥ì ì´ê³  ì‹ ë¢°í•˜ëŠ” ì„±í–¥)
        - ì‹ ê²½ì„± (ìŠ¤íŠ¸ë ˆìŠ¤ì— ëŒ€í•œ ë¯¼ê°ì„±)
        - ì°½ì˜ì„± (ì°½ì˜ì  ì‚¬ê³ ì™€ í˜ì‹ ì„±)
        - ê¸°ìˆ  ì¹œí™”ë„ (ê¸°ìˆ  ìˆ˜ìš©ê³¼ í™œìš© ëŠ¥ë ¥)
        
        ê° ì ìˆ˜ì— ëŒ€í•œ ê·¼ê±°ë„ í•¨ê»˜ ì œì‹œí•´ì£¼ì„¸ìš”.
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ì‹¬ë¦¬í•™ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë””ì§€í„¸ í–‰ë™ íŒ¨í„´ì„ í†µí•´ ì„±ê²© íŠ¹ì„±ì„ ì •í™•íˆ ë¶„ì„í•´ì£¼ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": traits_prompt
                    }
                ],
                max_tokens=1000,
                temperature=0.6
            )
            
            return self._parse_personality_response(response.choices[0].message.content)
            
        except Exception as e:
            print(f"ì„±ê²© íŠ¹ì„± ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._get_basic_personality()
    
    def _generate_recommendations(self, data_summary: Dict[str, Any]) -> Dict[str, List[str]]:
        """ê°œì¸í™”ëœ ì¶”ì²œ ìƒì„±"""
        if not self.ai_enabled:
            return self._get_basic_recommendations()
        
        # numpy íƒ€ì…ì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
        clean_data = convert_numpy_types(data_summary)
        
        rec_prompt = f"""
        ë‹¤ìŒ ì‚¬ìš©ì í”„ë¡œí•„ì„ ë°”íƒ•ìœ¼ë¡œ ê°œì¸í™”ëœ ì¶”ì²œì„ ìƒì„±í•´ì£¼ì„¸ìš”:
        
        {json.dumps(clean_data, ensure_ascii=False, indent=2)}
        
        ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë³„ë¡œ êµ¬ì²´ì ì¸ ì¶”ì²œì„ ì œì‹œí•´ì£¼ì„¸ìš”:
        1. ìƒì‚°ì„± ë„êµ¬ (ì—…ë¬´ íš¨ìœ¨ì„± í–¥ìƒ)
        2. í•™ìŠµ ë¦¬ì†ŒìŠ¤ (ê¸°ìˆ  ë° ì§€ì‹ í–¥ìƒ)
        3. ì†Œí”„íŠ¸ì›¨ì–´/ì•± (í˜„ì¬ ì‚¬ìš© íŒ¨í„´ ê¸°ë°˜)
        4. ì—…ë¬´ ìŠ¤íƒ€ì¼ ê°œì„  (ë” ë‚˜ì€ ì‘ì—… í™˜ê²½)
        5. ì»¤ë¦¬ì–´ ë°œì „ (ì„±í–¥ì— ë§ëŠ” ë°©í–¥ì„±)
        
        ê° ì¹´í…Œê³ ë¦¬ë‹¹ 3-5ê°œì˜ êµ¬ì²´ì ì¸ ì¶”ì²œì„ í•´ì£¼ì„¸ìš”.
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ê°œì¸ ìƒì‚°ì„± ë° ì»¤ë¦¬ì–´ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ë””ì§€í„¸ íŒ¨í„´ì„ ë°”íƒ•ìœ¼ë¡œ ì‹¤ìš©ì ì¸ ì¶”ì²œì„ ì œê³µí•´ì£¼ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": rec_prompt
                    }
                ],
                max_tokens=1200,
                temperature=0.7
            )
            
            return self._parse_recommendations_response(response.choices[0].message.content)
            
        except Exception as e:
            print(f"ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: {e}")
            return self._get_basic_recommendations()
    
    def _create_analysis_prompt(self, data_summary: Dict[str, Any]) -> str:
        """ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return f"""
        ì‚¬ìš©ìì˜ ë””ì§€í„¸ ì‚¬ìš© íŒ¨í„´ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
        
        ğŸ“Š ìˆ˜ì§‘ëœ ë°ì´í„°:
        - ë¶ë§ˆí¬ ì¹´í…Œê³ ë¦¬: {data_summary.get('bookmark_categories', [])}
        - ë¸Œë¼ìš°ì € íˆìŠ¤í† ë¦¬: {data_summary.get('top_sites', [])}
        - ì„¤ì¹˜ëœ í”„ë¡œê·¸ë¨: {data_summary.get('software_categories', {})}
        - Chrome í™•ì¥ í”„ë¡œê·¸ë¨: {data_summary.get('extensions', [])}
        - ìµœê·¼ ì‚¬ìš© íŒŒì¼: {data_summary.get('recent_files', [])}
        - ë„¤íŠ¸ì›Œí¬ í™œë™: {data_summary.get('network_stats', {})}
        
        ğŸ“ˆ í†µê³„:
        - ì´ ë¶ë§ˆí¬ ìˆ˜: {data_summary.get('total_bookmarks', 0)}
        - ì´ ë°©ë¬¸ ì‚¬ì´íŠ¸: {data_summary.get('total_visits', 0)}
        - ì„¤ì¹˜ëœ í”„ë¡œê·¸ë¨ ìˆ˜: {data_summary.get('total_programs', 0)}
        
        ì´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
        1. ì „ë°˜ì ì¸ ë””ì§€í„¸ ì‚¬ìš© ì„±í–¥
        2. ì£¼ìš” ê°•ì ê³¼ íŠ¹ì§•
        3. ì—…ë¬´ ìŠ¤íƒ€ì¼ê³¼ ì„ í˜¸ë„
        4. ê´€ì‹¬ ë¶„ì•¼ì™€ ì „ë¬¸ì„±
        """
    
    def _parse_ai_response(self, response: str) -> Dict[str, str]:
        """AI ì‘ë‹µì„ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ íŒŒì‹±"""
        print(f"ğŸ” AI ì‘ë‹µ íŒŒì‹± ì¤‘... (ì‘ë‹µ ê¸¸ì´: {len(response)})")
        
        # ë¨¼ì € JSON í˜•ì‹ì¸ì§€ í™•ì¸
        try:
            json_response = json.loads(response)
            if isinstance(json_response, dict):
                return {
                    'overview': json_response.get('overview', json_response.get('ì „ë°˜ì _ì„±í–¥', '')),
                    'strengths': json_response.get('strengths', json_response.get('ì£¼ìš”_ê°•ì ', '')),
                    'work_style': json_response.get('work_style', json_response.get('ì—…ë¬´_ìŠ¤íƒ€ì¼', '')),
                    'interests': json_response.get('interests', json_response.get('ê´€ì‹¬_ë¶„ì•¼', ''))
                }
        except:
            pass
        
        # í…ìŠ¤íŠ¸ íŒŒì‹±
        lines = response.split('\n')
        
        result = {
            'overview': '',
            'strengths': '',
            'work_style': '',
            'interests': ''
        }
        
        current_section = 'overview'
        content_found = False
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # ì„¹ì…˜ êµ¬ë¶„ì ê°ì§€
            if any(keyword in line for keyword in ['ê°•ì ', 'strength', 'ì¥ì ']):
                current_section = 'strengths'
                continue
            elif any(keyword in line for keyword in ['ì—…ë¬´', 'work', 'ìŠ¤íƒ€ì¼', 'ì‘ì—…']):
                current_section = 'work_style'
                continue
            elif any(keyword in line for keyword in ['ê´€ì‹¬', 'interest', 'ì·¨ë¯¸', 'ë¶„ì•¼']):
                current_section = 'interests'
                continue
            elif any(keyword in line for keyword in ['ì„±í–¥', 'íŠ¹ì§•', 'ë¶„ì„', 'ê°œìš”']):
                current_section = 'overview'
                continue
            
            # ë‚´ìš© ì¶”ê°€ (ë¶ˆí•„ìš”í•œ ê¸°í˜¸ ì œê±°)
            clean_line = line.replace('**', '').replace('##', '').replace('- ', '').strip()
            if clean_line and not clean_line.startswith('#'):
                result[current_section] += clean_line + ' '
                content_found = True
        
        # íŒŒì‹±ëœ ë‚´ìš©ì´ ì—†ìœ¼ë©´ ì „ì²´ ì‘ë‹µì„ overviewì— ì €ì¥
        if not content_found:
            result['overview'] = response[:500] + '...' if len(response) > 500 else response
        
        # ë¹ˆ ì„¹ì…˜ì— ê¸°ë³¸ê°’ ì„¤ì •
        for key, value in result.items():
            if not value.strip():
                result[key] = f"AI ë¶„ì„ ê²°ê³¼ë¥¼ {key} í•­ëª©ìœ¼ë¡œ ë¶„ë¥˜í•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤."
        
        print(f"âœ… AI ì‘ë‹µ íŒŒì‹± ì™„ë£Œ - ì„¹ì…˜ë³„ ê¸¸ì´: {[(k, len(v)) for k, v in result.items()]}")
        return result
    
    def _parse_mbti_text(self, response: str) -> Dict[str, Any]:
        """MBTI í…ìŠ¤íŠ¸ ì‘ë‹µ íŒŒì‹±"""
        print(f"ğŸ§  MBTI ì‘ë‹µ íŒŒì‹± ì¤‘... (ì‘ë‹µ ê¸¸ì´: {len(response)})")
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        result = {
            'E_I': {'score': 60, 'tendency': 'E', 'description': 'ì™¸í–¥ì  ì„±í–¥ìœ¼ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.'},
            'S_N': {'score': 50, 'tendency': 'S', 'description': 'ê°ê°ì  ì„±í–¥ìœ¼ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.'},
            'T_F': {'score': 65, 'tendency': 'T', 'description': 'ë…¼ë¦¬ì  ì‚¬ê³  ì„±í–¥ìœ¼ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.'},
            'J_P': {'score': 55, 'tendency': 'J', 'description': 'ê³„íšì  ì„±í–¥ìœ¼ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.'},
            'predicted_type': 'ESTJ',
            'confidence': 70
        }
        
        # ì‘ë‹µì—ì„œ ì ìˆ˜ ì¶”ì¶œ ì‹œë„
        import re
        
        # E/I ì ìˆ˜ ì°¾ê¸°
        ei_match = re.search(r'[EI].*?(\d+)', response)
        if ei_match:
            score = int(ei_match.group(1))
            result['E_I']['score'] = score
            result['E_I']['tendency'] = 'E' if score > 50 else 'I'
            result['E_I']['description'] = f"{'ì™¸í–¥ì ' if score > 50 else 'ë‚´í–¥ì '} ì„±í–¥ {score}%"
        
        # S/N ì ìˆ˜ ì°¾ê¸°
        sn_match = re.search(r'[SN].*?(\d+)', response)
        if sn_match:
            score = int(sn_match.group(1))
            result['S_N']['score'] = score
            result['S_N']['tendency'] = 'S' if score > 50 else 'N'
            result['S_N']['description'] = f"{'ê°ê°ì ' if score > 50 else 'ì§ê´€ì '} ì„±í–¥ {score}%"
        
        # T/F ì ìˆ˜ ì°¾ê¸°
        tf_match = re.search(r'[TF].*?(\d+)', response)
        if tf_match:
            score = int(tf_match.group(1))
            result['T_F']['score'] = score
            result['T_F']['tendency'] = 'T' if score > 50 else 'F'
            result['T_F']['description'] = f"{'ì‚¬ê³ í˜•' if score > 50 else 'ê°ì •í˜•'} ì„±í–¥ {score}%"
        
        # J/P ì ìˆ˜ ï¿½ê¸°
        jp_match = re.search(r'[JP].*?(\d+)', response)
        if jp_match:
            score = int(jp_match.group(1))
            result['J_P']['score'] = score
            result['J_P']['tendency'] = 'J' if score > 50 else 'P'
            result['J_P']['description'] = f"{'íŒë‹¨í˜•' if score > 50 else 'ì¸ì‹í˜•'} ì„±í–¥ {score}%"
        
        # MBTI ìœ í˜• ê²°ì •
        mbti_type = (result['E_I']['tendency'] + 
                    result['S_N']['tendency'] + 
                    result['T_F']['tendency'] + 
                    result['J_P']['tendency'])
        result['predicted_type'] = mbti_type
        
        # ì‹ ë¢°ë„ ê³„ì‚° (í‰ê·  ì ìˆ˜ ê¸°ë°˜)
        scores = [abs(result[key]['score'] - 50) for key in ['E_I', 'S_N', 'T_F', 'J_P']]
        result['confidence'] = min(90, max(60, int(sum(scores) / len(scores) * 2 + 50)))
        
        print(f"âœ… MBTI íŒŒì‹± ì™„ë£Œ - ìœ í˜•: {mbti_type}, ì‹ ë¢°ë„: {result['confidence']}%")
        return result
    
    def _parse_personality_response(self, response: str) -> Dict[str, Any]:
        """ì„±ê²© íŠ¹ì„± ì‘ë‹µ íŒŒì‹±"""
        print(f"ğŸ¯ ì„±ê²© íŠ¹ì„± ì‘ë‹µ íŒŒì‹± ì¤‘... (ì‘ë‹µ ê¸¸ì´: {len(response)})")
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        result = {
            'openness': {'score': 75, 'description': 'ìƒˆë¡œìš´ ê²½í—˜ì— ê°œë°©ì ì¸ ì„±í–¥ì„ ë³´ì…ë‹ˆë‹¤.'},
            'conscientiousness': {'score': 68, 'description': 'ì„±ì‹¤í•˜ê³  ì¡°ì§ì ì¸ ì„±í–¥ì„ ë³´ì…ë‹ˆë‹¤.'},
            'extraversion': {'score': 62, 'description': 'ì‚¬êµì ì´ê³  í™œë™ì ì¸ ì„±í–¥ì„ ë³´ì…ë‹ˆë‹¤.'},
            'agreeableness': {'score': 71, 'description': 'í˜‘ë ¥ì ì´ê³  ì¹œí™”ì ì¸ ì„±í–¥ì„ ë³´ì…ë‹ˆë‹¤.'},
            'neuroticism': {'score': 35, 'description': 'ì •ì„œì ìœ¼ë¡œ ì•ˆì •ì ì¸ ì„±í–¥ì„ ë³´ì…ë‹ˆë‹¤.'},
            'creativity': {'score': 78, 'description': 'ì°½ì˜ì ì´ê³  í˜ì‹ ì ì¸ ì‚¬ê³ ë¥¼ ë³´ì…ë‹ˆë‹¤.'},
            'tech_savviness': {'score': 85, 'description': 'ê¸°ìˆ ì— ëŠ¥ìˆ™í•˜ê³  ì ì‘ë ¥ì´ ë›°ì–´ë‚©ë‹ˆë‹¤.'}
        }
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            json_response = json.loads(response)
            if isinstance(json_response, dict):
                for key in result.keys():
                    if key in json_response:
                        if isinstance(json_response[key], dict):
                            result[key].update(json_response[key])
                        elif isinstance(json_response[key], (int, float)):
                            result[key]['score'] = int(json_response[key])
                return result
        except:
            pass
        
        # í…ìŠ¤íŠ¸ì—ì„œ ì ìˆ˜ ì¶”ì¶œ
        import re
        
        # ê° íŠ¹ì„±ë³„ ì ìˆ˜ ì°¾ê¸°
        traits_mapping = {
            'openness': ['ê°œë°©ì„±', 'openness', 'ê°œë°©ì '],
            'conscientiousness': ['ì„±ì‹¤ì„±', 'conscientiousness', 'ì„±ì‹¤'],
            'extraversion': ['ì™¸í–¥ì„±', 'extraversion', 'ì™¸í–¥ì '],
            'agreeableness': ['ì¹œí™”ì„±', 'agreeableness', 'ì¹œí™”ì '],
            'neuroticism': ['ì‹ ê²½ì„±', 'neuroticism', 'ë¶ˆì•ˆ'],
            'creativity': ['ì°½ì˜ì„±', 'creativity', 'ì°½ì˜ì '],
            'tech_savviness': ['ê¸°ìˆ ', 'tech', 'í…Œí¬']
        }
        
        for trait, keywords in traits_mapping.items():
            for keyword in keywords:
                # í‚¤ì›Œë“œ ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” ìˆ«ì ì°¾ê¸°
                pattern = rf'{keyword}.*?(\d+)'
                match = re.search(pattern, response, re.IGNORECASE)
                if match:
                    score = int(match.group(1))
                    if 0 <= score <= 100:
                        result[trait]['score'] = score
                        result[trait]['description'] = f"{keyword} ì ìˆ˜: {score}ì "
                        break
        
        print(f"âœ… ì„±ê²© íŠ¹ì„± íŒŒì‹± ì™„ë£Œ - í‰ê·  ì ìˆ˜: {sum(t['score'] for t in result.values()) / len(result):.1f}")
        return result
    
    def _parse_recommendations_response(self, response: str) -> Dict[str, List[str]]:
        """ì¶”ì²œ ì‘ë‹µ íŒŒì‹±"""
        print(f"ğŸ’¡ ì¶”ì²œ ì‚¬í•­ ì‘ë‹µ íŒŒì‹± ì¤‘... (ì‘ë‹µ ê¸¸ì´: {len(response)})")
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        result = {
            'productivity_tools': ['Notion - ì˜¬ì¸ì› ì›Œí¬ìŠ¤í˜ì´ìŠ¤', 'Todoist - ì‘ì—… ê´€ë¦¬', 'RescueTime - ì‹œê°„ ì¶”ì '],
            'learning_resources': ['Coursera - ì˜¨ë¼ì¸ ê°•ì˜', 'YouTube - ë¬´ë£Œ íŠœí† ë¦¬ì–¼', 'Stack Overflow - ê°œë°œ Q&A'],
            'software_apps': ['VS Code - ì½”ë“œ ì—ë””í„°', 'Chrome - ì›¹ ë¸Œë¼ìš°ì €', 'Slack - íŒ€ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜'],
            'work_style': ['ì •ê¸°ì ì¸ íœ´ì‹ ì‹œê°„ í™•ë³´', 'ì‘ì—… ìš°ì„ ìˆœìœ„ ì„¤ì •', 'ì§‘ì¤‘ ì‹œê°„ ë¸”ë¡ í™œìš©'],
            'career_development': ['ê¸°ìˆ  ë¸”ë¡œê·¸ ì‘ì„±', 'ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ ì°¸ì—¬', 'ë„¤íŠ¸ì›Œí‚¹ ì´ë²¤íŠ¸ ì°¸ì„']
        }
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            json_response = json.loads(response)
            if isinstance(json_response, dict):
                for key in result.keys():
                    if key in json_response and isinstance(json_response[key], list):
                        result[key] = json_response[key]
                return result
        except:
            pass
        
        # í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì²œ ì‚¬í•­ ì¶”ì¶œ
        lines = response.split('\n')
        current_category = None
        
        categories_mapping = {
            'productivity_tools': ['ìƒì‚°ì„±', 'productivity', 'ë„êµ¬', 'tool'],
            'learning_resources': ['í•™ìŠµ', 'learning', 'êµìœ¡', 'education', 'ë¦¬ì†ŒìŠ¤'],
            'software_apps': ['ì†Œí”„íŠ¸ì›¨ì–´', 'software', 'ì•±', 'app', 'í”„ë¡œê·¸ë¨'],
            'work_style': ['ì—…ë¬´', 'work', 'ìŠ¤íƒ€ì¼', 'style', 'ë°©ì‹'],
            'career_development': ['ì»¤ë¦¬ì–´', 'career', 'ë°œì „', 'development', 'ì„±ì¥']
        }
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # ì¹´í…Œê³ ë¦¬ ê°ì§€
            for category, keywords in categories_mapping.items():
                if any(keyword in line.lower() for keyword in keywords):
                    current_category = category
                    result[category] = []  # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ì´ˆê¸°í™”
                    break
            
            # ì¶”ì²œ í•­ëª© ì¶”ì¶œ (-, *, ìˆ«ìë¡œ ì‹œì‘í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ í•­ëª©)
            if current_category and (line.startswith('-') or line.startswith('*') or 
                                   line.startswith('â€¢') or any(line.startswith(f'{i}.') for i in range(1, 10))):
                item = line.lstrip('-*â€¢0123456789. ').strip()
                if item and len(item) > 3:  # ë„ˆë¬´ ì§§ì€ í•­ëª© ì œì™¸
                    result[current_category].append(item)
        
        # ë¹ˆ ì¹´í…Œê³ ë¦¬ì— ê¸°ë³¸ ì¶”ì²œ ìœ ì§€
        for category, items in result.items():
            if not items:
                if category == 'productivity_tools':
                    result[category] = ['Notion', 'Trello', 'Todoist']
                elif category == 'learning_resources':
                    result[category] = ['ì˜¨ë¼ì¸ ê°•ì˜ í”Œë«í¼', 'ê¸°ìˆ  ë¸”ë¡œê·¸', 'ì „ë¬¸ ì„œì ']
                elif category == 'software_apps':
                    result[category] = ['ê°œë°œ ë„êµ¬', 'ë””ìì¸ ì†Œí”„íŠ¸ì›¨ì–´', 'ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì•±']
                elif category == 'work_style':
                    result[category] = ['ì²´ê³„ì  ê³„íš ìˆ˜ë¦½', 'ì •ê¸°ì  ê²€í† ', 'íš¨ìœ¨ì  ì‹œê°„ ê´€ë¦¬']
                elif category == 'career_development':
                    result[category] = ['ì§€ì†ì  í•™ìŠµ', 'ë„¤íŠ¸ì›Œí‚¹', 'í”„ë¡œì íŠ¸ ê²½í—˜ ìŒ“ê¸°']
        
        total_recommendations = sum(len(items) for items in result.values())
        print(f"âœ… ì¶”ì²œ ì‚¬í•­ íŒŒì‹± ì™„ë£Œ - ì´ {total_recommendations}ê°œ ì¶”ì²œ")
        return result
    
    def _get_basic_analysis(self, data_summary: Dict[str, Any]) -> Dict[str, Any]:
        """AI ì—†ì´ ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰"""
        return {
            'ai_insights': {
                'overview': 'ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¸°ë³¸ ë¶„ì„ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.',
                'strengths': 'ë‹¤ì–‘í•œ ë””ì§€í„¸ ë„êµ¬ë¥¼ í™œìš©í•˜ëŠ” ëŠ¥ë ¥ì´ ìˆìŠµë‹ˆë‹¤.',
                'work_style': 'ì²´ê³„ì ì´ê³  íš¨ìœ¨ì ì¸ ì‘ì—… ë°©ì‹ì„ ì„ í˜¸í•©ë‹ˆë‹¤.',
                'interests': 'ê¸°ìˆ ê³¼ ìƒì‚°ì„±ì— ê´€ì‹¬ì´ ë§ìŠµë‹ˆë‹¤.'
            },
            'mbti_analysis': self._get_basic_mbti(),
            'personality_traits': self._get_basic_personality(),
            'recommendations': self._get_basic_recommendations(),
            'analysis_timestamp': datetime.now().isoformat(),
            'ai_powered': False
        }
    
    def _get_basic_mbti(self) -> Dict[str, Any]:
        """ê¸°ë³¸ MBTI ë¶„ì„"""
        return {
            'E_I': {'score': 60, 'tendency': 'E', 'description': 'ì†Œì…œ ë„êµ¬ ì‚¬ìš© íŒ¨í„´ ê¸°ë°˜ ë¶„ì„'},
            'S_N': {'score': 45, 'tendency': 'S', 'description': 'ì‹¤ìš©ì  ë„êµ¬ ì„ í˜¸ ê²½í–¥'},
            'T_F': {'score': 65, 'tendency': 'T', 'description': 'ë…¼ë¦¬ì  ë„êµ¬ ì‚¬ìš© íŒ¨í„´'},
            'J_P': {'score': 55, 'tendency': 'J', 'description': 'ì²´ê³„ì  íŒŒì¼ ê´€ë¦¬ íŒ¨í„´'},
            'predicted_type': 'ESTJ',
            'confidence': 60
        }
    
    def _get_basic_personality(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ì„±ê²© íŠ¹ì„±"""
        return {
            'openness': {'score': 70, 'description': 'ë‹¤ì–‘í•œ ë„êµ¬ì™€ ê¸°ìˆ  ì‚¬ìš©'},
            'conscientiousness': {'score': 65, 'description': 'ì²´ê³„ì ì¸ íŒŒì¼ ê´€ë¦¬'},
            'extraversion': {'score': 60, 'description': 'í˜‘ì—… ë„êµ¬ ì‚¬ìš© íŒ¨í„´'},
            'agreeableness': {'score': 70, 'description': 'ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ë„êµ¬ í™œìš©'},
            'neuroticism': {'score': 40, 'description': 'ì•ˆì •ì ì¸ ì‚¬ìš© íŒ¨í„´'},
            'creativity': {'score': 75, 'description': 'ì°½ì‘ ë„êµ¬ ì‚¬ìš©'},
            'tech_savviness': {'score': 80, 'description': 'ê³ ê¸‰ ê¸°ìˆ  ë„êµ¬ í™œìš©'}
        }
    
    def _get_basic_recommendations(self) -> Dict[str, List[str]]:
        """ê¸°ë³¸ ì¶”ì²œ"""
        return {
            'productivity_tools': [
                'Notion - í†µí•© ì›Œí¬ìŠ¤í˜ì´ìŠ¤',
                'Todoist - ì‘ì—… ê´€ë¦¬',
                'RescueTime - ì‹œê°„ ì¶”ì '
            ],
            'learning_resources': [
                'Coursera - ì˜¨ë¼ì¸ ê°•ì˜',
                'Udemy - ê¸°ìˆ  êµìœ¡',
                'LinkedIn Learning - ì „ë¬¸ ìŠ¤í‚¬'
            ],
            'software_apps': [
                'VS Code - ì½”ë“œ ì—ë””í„°',
                'Figma - ë””ìì¸ ë„êµ¬',
                'Slack - íŒ€ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜'
            ],
            'work_style': [
                'í¬ëª¨ë„ë¡œ ê¸°ë²• í™œìš©',
                'ì •ê¸°ì ì¸ ë°±ì—… ìŠµê´€',
                'í‚¤ë³´ë“œ ë‹¨ì¶•í‚¤ í•™ìŠµ'
            ],
            'career_development': [
                'ê¸°ìˆ  ë¸”ë¡œê·¸ ì‘ì„±',
                'ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ ì°¸ì—¬',
                'ì˜¨ë¼ì¸ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì¶•'
            ]
        }

def prepare_data_for_ai_analysis(uploads_dir: str) -> Dict[str, Any]:
    """ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ AI ë¶„ì„ìš©ìœ¼ë¡œ ì¤€ë¹„"""
    data_summary = {
        'bookmark_categories': [],
        'top_sites': [],
        'software_categories': {},
        'extensions': [],
        'recent_files': [],
        'network_stats': {},
        'total_bookmarks': 0,
        'total_visits': 0,
        'total_programs': 0
    }
    
    try:
        # ë¶ë§ˆí¬ ë°ì´í„° ì²˜ë¦¬
        bookmark_files = [f for f in os.listdir(uploads_dir) if f.startswith('bookmarks_') and f.endswith('.csv')]
        if bookmark_files:
            latest_bookmark = max(bookmark_files, key=lambda f: os.path.getctime(os.path.join(uploads_dir, f)))
            df_bookmarks = pd.read_csv(os.path.join(uploads_dir, latest_bookmark))
            
            if 'folder' in df_bookmarks.columns:
                data_summary['bookmark_categories'] = df_bookmarks['folder'].value_counts().head(10).to_dict()
            data_summary['total_bookmarks'] = len(df_bookmarks)
        
        # íˆìŠ¤í† ë¦¬ ë°ì´í„° ì²˜ë¦¬
        history_files = [f for f in os.listdir(uploads_dir) if f.startswith('browser_history_') and f.endswith('.csv')]
        if history_files:
            latest_history = max(history_files, key=lambda f: os.path.getctime(os.path.join(uploads_dir, f)))
            df_history = pd.read_csv(os.path.join(uploads_dir, latest_history))
            
            if 'domain' in df_history.columns:
                data_summary['top_sites'] = df_history['domain'].value_counts().head(10).to_dict()
            if 'visit_count' in df_history.columns:
                data_summary['total_visits'] = df_history['visit_count'].sum()
        
        # í™•ì¥ í”„ë¡œê·¸ë¨ ë°ì´í„° ì²˜ë¦¬
        extension_files = [f for f in os.listdir(uploads_dir) if f.startswith('chrome_extensions_') and f.endswith('.csv')]
        if extension_files:
            latest_extensions = max(extension_files, key=lambda f: os.path.getctime(os.path.join(uploads_dir, f)))
            df_extensions = pd.read_csv(os.path.join(uploads_dir, latest_extensions))
            
            if 'category' in df_extensions.columns:
                data_summary['extensions'] = df_extensions['category'].value_counts().to_dict()
        
        # ì„¤ì¹˜ëœ í”„ë¡œê·¸ë¨ ë°ì´í„° ì²˜ë¦¬
        program_files = [f for f in os.listdir(uploads_dir) if f.startswith('installed_programs_') and f.endswith('.csv')]
        if program_files:
            latest_programs = max(program_files, key=lambda f: os.path.getctime(os.path.join(uploads_dir, f)))
            df_programs = pd.read_csv(os.path.join(uploads_dir, latest_programs))
            
            if 'category' in df_programs.columns:
                data_summary['software_categories'] = df_programs['category'].value_counts().to_dict()
            data_summary['total_programs'] = len(df_programs)
        
        # ìµœê·¼ íŒŒì¼ ë°ì´í„° ì²˜ë¦¬
        recent_files = [f for f in os.listdir(uploads_dir) if f.startswith('recent_files_') and f.endswith('.csv')]
        if recent_files:
            latest_recent = max(recent_files, key=lambda f: os.path.getctime(os.path.join(uploads_dir, f)))
            df_recent = pd.read_csv(os.path.join(uploads_dir, latest_recent))
            
            if 'category' in df_recent.columns:
                data_summary['recent_files'] = df_recent['category'].value_counts().to_dict()
        
        # ë„¤íŠ¸ì›Œí¬ ì •ë³´ ì²˜ë¦¬
        network_files = [f for f in os.listdir(uploads_dir) if f.startswith('network_info_') and f.endswith('.csv')]
        if network_files:
            latest_network = max(network_files, key=lambda f: os.path.getctime(os.path.join(uploads_dir, f)))
            df_network = pd.read_csv(os.path.join(uploads_dir, latest_network))
            
            if 'category' in df_network.columns:
                data_summary['network_stats'] = df_network['category'].value_counts().to_dict()
    
    except Exception as e:
        print(f"ë°ì´í„° ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜: {e}")
    
    # numpy íƒ€ì…ì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
    return convert_numpy_types(data_summary)
